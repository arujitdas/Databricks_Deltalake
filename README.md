A Data Lake makes our life easy by storing massive data from diverse data sources so that further insights could be gained from this vast data.
Although, Data Lake has been in place for a couple of good amount of time meeting business demands, there is a need for the following parameters
1.	ACID Transaction
2.	Schema Enforcement and Evolution
3.	Time Travel
4.	Unified Batch and Streaming
5.	Full DML support

In the attached notebook, I will try to explain the above parameters with a hands-on use case and with the help of Databricks Delta lake
